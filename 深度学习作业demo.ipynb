{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba2f3593",
   "metadata": {},
   "source": [
    "这个是深度学习课后的小作业，主要是给大家再熟悉一下模型训练的流程，让大家体验一下。我们这里的任务是对10个类别的“时装”图像进行分类，使用[FashionMNIST数据集](https://github.com/zalandoresearch/fashion-mnist/tree/master/data/fashion )。 \n",
    "FashionMNIST数据集中包含已经预先划分好的训练集和测试集，其中训练集共60,000张图像，测试集共10,000张图像。每张图像均为单通道黑白图像，大小为28\\*28pixel，分属10个类别。  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd159071",
   "metadata": {},
   "source": [
    "**首先导入必要的包** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "927d4420",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121e9da3",
   "metadata": {},
   "source": [
    "**配置训练环境和超参数** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2392e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置GPU，这里有两种方式\n",
    "## 方案一：使用os.environ\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "# 方案二：使用“device”，后续对要使用GPU的变量用.to(device)即可\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "## 配置其他超参数，如batch_size, num_workers, learning rate, 以及总的epochs\n",
    "batch_size = 256\n",
    "num_workers = 0   # 对于Windows用户，这里应设置为0，否则会出现多线程错误\n",
    "lr = 1e-4\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e06dc2",
   "metadata": {},
   "source": [
    "**数据读入和加载**  \n",
    "这里同时展示两种方式:  \n",
    "- 下载并使用PyTorch提供的内置数据集  \n",
    "- 从网站下载以csv格式存储的数据，读入并转成预期的格式    \n",
    "第一种数据读入方式只适用于常见的数据集，如MNIST，CIFAR10等，PyTorch官方提供了数据下载。这种方式往往适用于快速测试方法（比如测试下某个idea在MNIST数据集上是否有效）  \n",
    "第二种数据读入方式需要自己构建Dataset，这对于PyTorch应用于自己的工作中十分重要  \n",
    "  \n",
    "同时，还需要对数据进行必要的变换，比如说需要将图片统一为一致的大小，以便后续能够输入网络训练；需要将数据格式转为Tensor类，等等。\n",
    "  \n",
    "**我们实际比赛的时候数据加载和处理是一个非常关键的步骤。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3947bbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先设置数据变换\n",
    "from torchvision import transforms\n",
    "\n",
    "image_size = 28\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),  \n",
    "     # 这一步取决于后续的数据读取方式，如果使用内置数据集读取方式则不需要\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a86217a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 读取方式一：使用torchvision自带数据集，下载可能需要一段时间\n",
    "# from torchvision import datasets\n",
    "\n",
    "# train_data = datasets.FashionMNIST(root='./', train=True, download=True, transform=data_transform)\n",
    "# test_data = datasets.FashionMNIST(root='./', train=False, download=True, transform=data_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e5a1003",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 读取方式二：读入csv格式的数据，自行构建Dataset类\n",
    "# csv数据下载链接：https://www.kaggle.com/zalando-research/fashionmnist\n",
    "class FMDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        self.images = df.iloc[:,1:].values.astype(np.uint8)\n",
    "        self.labels = df.iloc[:, 0].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx].reshape(28,28,1)\n",
    "        label = int(self.labels[idx])\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        else:\n",
    "            image = torch.tensor(image/255., dtype=torch.float)\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "        return image, label\n",
    "\n",
    "train_df = pd.read_csv(\"./fashion-mnist_train.csv\")\n",
    "test_df = pd.read_csv(\"./fashion-mnist_test.csv\")\n",
    "train_data = FMDataset(train_df, data_transform)\n",
    "test_data = FMDataset(test_df, data_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb0b8b1",
   "metadata": {},
   "source": [
    "在构建训练和测试数据集完成后，需要定义DataLoader类，以便在训练和测试时加载数据  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1d8f3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=num_workers, drop_last=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0069a065",
   "metadata": {},
   "source": [
    "读入后，我们可以做一些数据可视化操作，主要是验证我们读入的数据是否正确"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "784617fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1, 28, 28]) torch.Size([256])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2ac5dd5a3b0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "image, label = next(iter(train_loader))\n",
    "print(image.shape, label.shape)\n",
    "plt.imshow(image[0][0], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dded3b04",
   "metadata": {},
   "source": [
    "**模型设计**  \n",
    "由于任务较为简单，这里我们手搭一个CNN，而不考虑当下各种模型的复杂结构，模型构建完成后，将模型放到GPU上用于训练。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8817a6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Conv2d(32, 64, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64*4*4, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(-1, 64*4*4)\n",
    "        x = self.fc(x)\n",
    "        # x = nn.functional.normalize(x)\n",
    "        return x\n",
    "\n",
    "model = Net()\n",
    "model = model.cuda()\n",
    "# model = nn.DataParallel(model).cuda()   # 多卡训练时的写法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb67c0f8",
   "metadata": {},
   "source": [
    "**设定损失函数**  \n",
    "使用torch.nn模块自带的CrossEntropy损失  \n",
    "PyTorch会自动把整数型的label转为one-hot型，用于计算CE loss  \n",
    "这里需要确保label是从0开始的，同时模型不加softmax层（使用logits计算）,这也说明了PyTorch训练中各个部分不是独立的，需要通盘考虑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "680b8ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "# criterion = nn.CrossEntropyLoss(weight=[1,1,1,1,3,1,1,1,1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eda2704",
   "metadata": {},
   "source": [
    "**设定优化器**  \n",
    "这里我们使用Adam优化器 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0315515f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f395c64",
   "metadata": {},
   "source": [
    "**训练流程（自己写）**\n",
    "调⽤model.train()\n",
    "(1) 从train_dataloader中加载数据\n",
    "(2) 计算损失函数\n",
    "(3) 反向传播，优化器优化\n",
    "(4) print展⽰输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6cb6bd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()  # 设置为训练模式\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # 将数据移动到GPU\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "        \n",
    "        # 梯度清零\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 前向传播\n",
    "        output = model(data)\n",
    "        \n",
    "        # 计算损失\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "        \n",
    "        # 参数更新\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 统计信息\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = output.max(1)  # 获取预测类别\n",
    "        total += target.size(0)\n",
    "        correct += predicted.eq(target).sum().item()\n",
    "        \n",
    "        # 每100个batch打印一次进度\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} '\n",
    "                  f'({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
    "    \n",
    "    # 计算并打印epoch统计信息\n",
    "    accuracy = 100. * correct / total\n",
    "    avg_loss = train_loss / len(train_loader)\n",
    "    print(f'Epoch {epoch} Training - Average loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bdb39f",
   "metadata": {},
   "source": [
    "**验证流程（自己写）**\n",
    "关注两者的主要区别：  \n",
    "- 模型状态设置  \n",
    "- 是否需要初始化优化器\n",
    "- 是否需要将loss传回到网络\n",
    "- 是否需要每步更新optimizer  \n",
    "  \n",
    "此外，对于测试或验证过程，可以计算分类准确率，要求把结果print出来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a44cb93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    model.eval()  # 设置为评估模式\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():  # 不计算梯度，节省内存\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()\n",
    "            _, predicted = output.max(1)\n",
    "            total += target.size(0)\n",
    "            correct += predicted.eq(target).sum().item()\n",
    "    \n",
    "    accuracy = 100. * correct / total\n",
    "    avg_loss = test_loss / len(test_loader)\n",
    "    print(f'Epoch {epoch} Testing - Average loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\\n')\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f524f896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.300081\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.702950\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.403141\n",
      "Epoch 1 Training - Average loss: 0.6669, Accuracy: 75.17%\n",
      "Epoch 1 Testing - Average loss: 0.4607, Accuracy: 82.37%\n",
      "\n",
      "Best model saved with accuracy: 82.37%\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.455214\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.402406\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.396173\n",
      "Epoch 2 Training - Average loss: 0.4179, Accuracy: 84.78%\n",
      "Epoch 2 Testing - Average loss: 0.3368, Accuracy: 87.60%\n",
      "\n",
      "Best model saved with accuracy: 87.60%\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.382563\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.380712\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.379683\n",
      "Epoch 3 Training - Average loss: 0.3590, Accuracy: 86.78%\n",
      "Epoch 3 Testing - Average loss: 0.3145, Accuracy: 88.09%\n",
      "\n",
      "Best model saved with accuracy: 88.09%\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.318274\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.269146\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.252807\n",
      "Epoch 4 Training - Average loss: 0.3231, Accuracy: 88.18%\n",
      "Epoch 4 Testing - Average loss: 0.2721, Accuracy: 89.77%\n",
      "\n",
      "Best model saved with accuracy: 89.77%\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.338884\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.241118\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.389571\n",
      "Epoch 5 Training - Average loss: 0.3042, Accuracy: 88.73%\n",
      "Epoch 5 Testing - Average loss: 0.2650, Accuracy: 90.22%\n",
      "\n",
      "Best model saved with accuracy: 90.22%\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.283189\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.228009\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.237201\n",
      "Epoch 6 Training - Average loss: 0.2864, Accuracy: 89.39%\n",
      "Epoch 6 Testing - Average loss: 0.2484, Accuracy: 90.63%\n",
      "\n",
      "Best model saved with accuracy: 90.63%\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.231171\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.289446\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.223158\n",
      "Epoch 7 Training - Average loss: 0.2706, Accuracy: 89.88%\n",
      "Epoch 7 Testing - Average loss: 0.2413, Accuracy: 90.56%\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.307599\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.320326\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.293031\n",
      "Epoch 8 Training - Average loss: 0.2632, Accuracy: 90.22%\n",
      "Epoch 8 Testing - Average loss: 0.2324, Accuracy: 91.05%\n",
      "\n",
      "Best model saved with accuracy: 91.05%\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.226575\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.250183\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.225753\n",
      "Epoch 9 Training - Average loss: 0.2492, Accuracy: 90.82%\n",
      "Epoch 9 Testing - Average loss: 0.2284, Accuracy: 91.57%\n",
      "\n",
      "Best model saved with accuracy: 91.57%\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.248542\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.252983\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.217884\n",
      "Epoch 10 Training - Average loss: 0.2409, Accuracy: 91.02%\n",
      "Epoch 10 Testing - Average loss: 0.2210, Accuracy: 91.67%\n",
      "\n",
      "Best model saved with accuracy: 91.67%\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.280880\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.222138\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.192825\n",
      "Epoch 11 Training - Average loss: 0.2335, Accuracy: 91.35%\n",
      "Epoch 11 Testing - Average loss: 0.2245, Accuracy: 91.52%\n",
      "\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.220941\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 0.202475\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.297442\n",
      "Epoch 12 Training - Average loss: 0.2266, Accuracy: 91.47%\n",
      "Epoch 12 Testing - Average loss: 0.2399, Accuracy: 91.02%\n",
      "\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.281976\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 0.240122\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.184368\n",
      "Epoch 13 Training - Average loss: 0.2189, Accuracy: 91.77%\n",
      "Epoch 13 Testing - Average loss: 0.2060, Accuracy: 92.07%\n",
      "\n",
      "Best model saved with accuracy: 92.07%\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.194820\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.209680\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.245968\n",
      "Epoch 14 Training - Average loss: 0.2090, Accuracy: 92.20%\n",
      "Epoch 14 Testing - Average loss: 0.2151, Accuracy: 91.94%\n",
      "\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.175753\n",
      "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 0.222410\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 0.148808\n",
      "Epoch 15 Training - Average loss: 0.2051, Accuracy: 92.44%\n",
      "Epoch 15 Testing - Average loss: 0.2078, Accuracy: 92.10%\n",
      "\n",
      "Best model saved with accuracy: 92.10%\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.223393\n",
      "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 0.132139\n",
      "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 0.204587\n",
      "Epoch 16 Training - Average loss: 0.1961, Accuracy: 92.58%\n",
      "Epoch 16 Testing - Average loss: 0.2056, Accuracy: 92.43%\n",
      "\n",
      "Best model saved with accuracy: 92.43%\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.144924\n",
      "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 0.190152\n",
      "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 0.196741\n",
      "Epoch 17 Training - Average loss: 0.1906, Accuracy: 92.78%\n",
      "Epoch 17 Testing - Average loss: 0.2088, Accuracy: 91.98%\n",
      "\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.220238\n",
      "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 0.256515\n",
      "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 0.202444\n",
      "Epoch 18 Training - Average loss: 0.1866, Accuracy: 92.93%\n",
      "Epoch 18 Testing - Average loss: 0.2037, Accuracy: 92.49%\n",
      "\n",
      "Best model saved with accuracy: 92.49%\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.256745\n",
      "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 0.242489\n",
      "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 0.239569\n",
      "Epoch 19 Training - Average loss: 0.1842, Accuracy: 93.08%\n",
      "Epoch 19 Testing - Average loss: 0.2019, Accuracy: 92.44%\n",
      "\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 0.149271\n",
      "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 0.200023\n",
      "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 0.232778\n",
      "Epoch 20 Training - Average loss: 0.1774, Accuracy: 93.22%\n",
      "Epoch 20 Testing - Average loss: 0.1981, Accuracy: 92.46%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 记录最佳准确率\n",
    "best_acc = 0\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    train(epoch)\n",
    "    acc = test(epoch)\n",
    "    \n",
    "    # 保存最佳模型\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        torch.save(model.state_dict(), './FashionModel_best.pkl')\n",
    "        print(f'Best model saved with accuracy: {best_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9bf3c482",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"./FahionModel.pkl\"\n",
    "torch.save(model, save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
